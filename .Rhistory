bcl %>%
filter(Price >= input$priceInput[1],
Price <= input$priceInput[2],
Type == input$typeInput,
Country == input$countryInput
)
})
output$coolplot <- renderPlot({
if (is.null(filtered())) {
return()
}
ggplot(filtered(), aes(Alcohol_Content)) +
geom_histogram()
})
output$results <- renderTable({
filtered()
})
}
shinyApp(ui = ui, server = server)
install.packages("esquisse")
require(caret)
require(ggplot2)
require(highcharter)
require(dplyr)
data("diamonds")
require(DataExplorer)
create_report(diamonds)
install.packages(c("boot", "DT", "foreign", "MASS", "mime", "pillar", "RSQLite", "vctrs"))
create_report(diamonds)
require(DataExplorer)
create_report(diamonds)
pandoc_version()
require(devtools)
devtools::install_github("boxuancui/DataExplorer", ref = "develop")
.libPaths()
library(e1071)
?naiveBayes
#Next load the Titanic dataset
data(“Titanic”)
#Save into a data frame and view it
Titanic_df=as.data.frame(Titanic)
View(Titanic_df)
repeating_sequence=rep.int(seq_len(nrow(Titanic_df)), Titanic_df$Freq) #This will repeat each combination equal to the frequency of each combination
#Create the dataset by row repetition created
Titanic_dataset$Freq=NULL
#Create the dataset by row repetition created
Titanic_dataset=Titanic_df[repeating_sequence,]
#We no longer need the frequency, drop the feature
Titanic_dataset$Freq=NULL
View(Titanic_dataset)
repeating_sequence=rep.int(seq_len(nrow(Titanic_df)), Titanic_df$Freq) #This will repeat each combination equal to the frequency of each combination
#Create the dataset by row repetition created
Titanic_dataset=Titanic_df[repeating_sequence,]
Titanic_dataset$Freq=NULL
#Fitting the Naive Bayes model
Naive_Bayes_Model=naiveBayes(Survived ~., data=Titanic_dataset)
#What does the model say? Print the model summary
Naive_Bayes_Model
#Prediction on the dataset
NB_Predictions=predict(Naive_Bayes_Model,Titanic_dataset)
#Confusion matrix to check accuracy
table(NB_Predictions,Titanic_dataset$Survived)
NB_Predictions      No      Yes
No      1364    362
Yes     126     349
install.packages("mlr")
R.version
# installing/loading the package:
if(!require(installr)) {
install.packages("installr"); require(installr)} #load / install+load installr
# using the package:
updateR() # this will start the updating process of your R installation.
# It will check for newer versions, and if one is available, will guide you through the decisions you'd need to make
#read transactions
df_groceries <- read.csv("C:\\Users\\734904\\Desktop\\test.csv.txt")
str(df_groceries)
df_sorted <- df_groceries[order(df_groceries$Member_number),]
#read transactions
df_groceries <- read.csv("C:\\Users\\734904\\Desktop\\test.csv.txt")
str(df_groceries)
View(df_groceries)
df_sorted <- df_groceries[order(df_groceries$Member_number),]
#convert member number to numeric
df_sorted$Member_number <- as.numeric(df_sorted$Member_number)
View(df_sorted)
df_sorted$itemDescription <- as.factor(df_sorted$itemDescription)
str(df_sorted)
#group all the items that were bought together; by the same customer on the same date
library(plyr)
df_itemList <- ddply(df_groceries, c("Member_number","Date"), function(df1)paste(df1$itemDescription,collapse = ","))
View(df_sorted)
#remove member number and date
df_itemList$Member_number <- NULL
df_itemList$Date <- NULL
colnames(df_itemList) <- c("itemList")
View(df_itemList)
#write to csv format
write.csv(df_itemList,"D:\\Programs\\R\\R_Sessions\\test2.csv.txt", quote = FALSE, row.names = TRUE)
#load package required
library(arules)
#convert csv file to basket format
txn = read.transactions(file="ItemList.csv", rm.duplicates= FALSE, format="basket",sep=",",cols=1);
#convert csv file to basket format
txn = read.transactions(file="D:\\Programs\\R\\R_Sessions\\test2.csv.txt", rm.duplicates= FALSE, format="basket",sep=",",cols=1);
#remove quotes from transactions
txn@itemInfo$labels <- gsub("\"","",txn@itemInfo$labels)
#run apriori algorithm
basket_rules <- apriori(txn,parameter = list(minlen=2,sup = 0.001, conf = 0.01, target="rules"))
if(sessionInfo()['basePkgs']=="tm" | sessionInfo()['otherPkgs']=="tm"){
detach(package:sentiment, unload=TRUE)
detach(package:tm, unload=TRUE)
}
#view rules
inspect(basket_rules)
#convert to datframe and view; optional
df_basket <- as(basket_rules,"data.frame")
View(df_basket)
df_basket$confidence <- df_basket$confidence * 100
View(df_basket)
df_basket$support <- df_basket$support * nrow(df)
# split lhs and rhs into two columns
library(reshape2)
df_basket <- transform(df_basket, rules = colsplit(rules, pattern = "=>", names = c("lhs","rhs")))
View(df_basket)
# Remove curly brackets around rules
df_basket$rules$lhs <- gsub("[[:punct:]]", "", df_basket$rules$lhs)
df_basket$rules$rhs <- gsub("[[:punct:]]", "", df_basket$rules$rhs)
# convert to chracter
df_basket$rules$lhs <- as.character(df_basket$rules$lhs)
df_basket$rules$rhs <- as.character(df_basket$rules$rhs)
library(stringi)
library(dplyr)
df_basket$rules %>%
filter(stri_detect_fixed(lhs, "yogurt")) %>%
select(rhs)
View(df_basket)
#plot the rules
library(arulesViz)
plot(basket_rules)
set.seed(8000)
plot(basket_rules, method = "grouped", control = list(k = 5))
plot(basket_rules[1:10,], method="graph", control=list(type="items"))
plot(basket_rules[1:20,], method="graph", control=list(type="items"))
plot(basket_rules[1:10,], method="paracoord",  control=list(alpha=.5, reorder=TRUE))
itemFrequencyPlot(txn, topN = 5)
plot(basket_rules[1:10,],measure=c("support","lift"),shading="confidence",interactive=T)
#load package required
library(arules)
#convert csv file to basket format
txn = read.transactions(file="D:\\Programs\\R\\R_Sessions\\test2.csv.txt", rm.duplicates= FALSE, format="basket",sep=",",cols=1);
#remove quotes from transactions
txn@itemInfo$labels <- gsub("\"","",txn@itemInfo$labels)
#run apriori algorithm
basket_rules <- apriori(txn,parameter = list(minlen=2,sup = 0.001, conf = 0.01, target="rules"))
#basket_rules <- apriori(txn,parameter = list(minlen=2,sup = 0.00001, conf = 0.01, target="rules"),appearance = list(lhs = "CLEMENTINES")))
#check if tm is attched; if yes then detach
if(sessionInfo()['basePkgs']=="tm" | sessionInfo()['otherPkgs']=="tm"){
detach(package:sentiment, unload=TRUE)
detach(package:tm, unload=TRUE)
}
#view rules
inspect(basket_rules)
#convert to datframe and view; optional
df_basket <- as(basket_rules,"data.frame")
df_basket$confidence <- df_basket$confidence * 100
df_basket$support <- df_basket$support * nrow(df)
View(df_basket)
df_basket$support <- df_basket$support * 100
#read transactions
df_groceries <- read.csv("D:\\Programs\\R\\R_Sessions\\test.csv.txt")
str(df_groceries)
df_sorted <- df_groceries[order(df_groceries$Member_number),]
#convert member number to numeric
df_sorted$Member_number <- as.numeric(df_sorted$Member_number)
#convert item description to categorical format
df_sorted$itemDescription <- as.factor(df_sorted$itemDescription)
str(df_sorted)
#convert dataframe to transaction format using ddply;
if(sessionInfo()['basePkgs']=="dplyr" | sessionInfo()['otherPkgs']=="dplyr"){
detach(package:dplyr, unload=TRUE)
}
#group all the items that were bought together; by the same customer on the same date
library(plyr)
df_itemList <- ddply(df_groceries, c("Member_number","Date"), function(df1)paste(df1$itemDescription,collapse = ","))
#remove member number and date
df_itemList$Member_number <- NULL
df_itemList$Date <- NULL
colnames(df_itemList) <- c("itemList")
#write to csv format
write.csv(df_itemList,"D:\\Programs\\R\\R_Sessions\\test2.csv.txt", quote = FALSE, row.names = TRUE)
#-------------------- association rule mining algorithm : apriori -------------------------#
#load package required
library(arules)
#convert csv file to basket format
txn = read.transactions(file="D:\\Programs\\R\\R_Sessions\\test2.csv.txt", rm.duplicates= FALSE, format="basket",sep=",",cols=1);
#remove quotes from transactions
txn@itemInfo$labels <- gsub("\"","",txn@itemInfo$labels)
#run apriori algorithm
basket_rules <- apriori(txn,parameter = list(minlen=2,sup = 0.001, conf = 0.01, target="rules"))
#basket_rules <- apriori(txn,parameter = list(minlen=2,sup = 0.00001, conf = 0.01, target="rules"),appearance = list(lhs = "CLEMENTINES")))
#check if tm is attched; if yes then detach
if(sessionInfo()['basePkgs']=="tm" | sessionInfo()['otherPkgs']=="tm"){
detach(package:sentiment, unload=TRUE)
detach(package:tm, unload=TRUE)
}
#view rules
inspect(basket_rules)
#convert to datframe and view; optional
df_basket <- as(basket_rules,"data.frame")
install.packages(c("factoextra", "clustertend", "seriation"))
library(factoextra)
library(clustertend)
library(seriation)
data("faithful")
df <- faithful
head(df)
library("ggplot2")
ggplot(df, aes(x=eruptions, y=waiting)) +
geom_point() +  # Scatter plot
geom_density_2d() # Add 2d density estimation
library("ggplot2")
ggplot(df, aes(x=eruptions, y=waiting)) +
geom_point()   # Scatter plot
#geom_density_2d() # Add 2d density estimation
library("ggplot2")
ggplot(df, aes(x=eruptions, y=waiting)) +
geom_point() +  # Scatter plot
geom_density_2d() # Add 2d density estimation
# Generate random dataset
set.seed(123)
n <- nrow(df)
random_df <- data.frame(
x = runif(nrow(df), min(df$eruptions), max(df$eruptions)),
y = runif(nrow(df), min(df$waiting), max(df$waiting)))
# Plot the data
ggplot(random_df, aes(x, y)) + geom_point()
random_df <- apply(df, 2,
function(x, n){runif(n, min(x), (max(x)))}, n)
# Plot the data
ggplot(random_df, aes(x, y)) + geom_point()
# Plot the data
ggplot(random_df, aes(x, y)) + geom_point()
random_df <- data.frame(
x = runif(nrow(df), min(df$eruptions), max(df$eruptions)),
y = runif(nrow(df), min(df$waiting), max(df$waiting)))
# Plot the data
ggplot(random_df, aes(x, y)) + geom_point()
library(factoextra)
set.seed(123)
km.res1 <- kmeans(df, 2)
fviz_cluster(list(data = df, cluster = km.res1$cluster),
frame.type = "norm", geom = "point", stand = FALSE)
km.res1 <- kmeans(df, 3)
fviz_cluster(list(data = df, cluster = km.res1$cluster),
frame.type = "norm", geom = "point", stand = FALSE)
km.res1 <- kmeans(df, 2)
fviz_cluster(list(data = df, cluster = km.res1$cluster),
frame.type = "norm", geom = "point", stand = FALSE)
fviz_cluster(list(data = random_df, cluster = km.res2$cluster),
frame.type = "norm", geom = "point", stand = FALSE)
km.res2 <- kmeans(random_df, 2)
fviz_cluster(list(data = random_df, cluster = km.res2$cluster),
frame.type = "norm", geom = "point", stand = FALSE)
# Hierarchical clustering on the random dataset
fviz_dend(hclust(dist(random_df)), k = 2,  cex = 0.5)
library(clustertend)
# Compute Hopkins statistic for faithful dataset
set.seed(123)
hopkins(faithful, n = nrow(faithful)-1)
# Compute Hopkins statistic for a random dataset
set.seed(123)
hopkins(random_df, n = nrow(random_df)-1)
library("seriation")
# faithful data: ordered dissimilarity image
df_scaled <- scale(faithful)
df_dist <- dist(df_scaled)
dissplot(df_dist)
# faithful data: ordered dissimilarity image
random_df_scaled <- scale(random_df)
random_df_dist <- dist(random_df_scaled)
dissplot(random_df_dist)
# K-means on the random dataset
km.res2 <- kmeans(random_df, 3)
fviz_cluster(list(data = random_df, cluster = km.res2$cluster),
ellipse.type = "norm", geom = "point", stand = FALSE,
palette = "jco", ggtheme = theme_classic())
fviz_dend(hclust(dist(random_df)), k = 3, k_colors = "jco",
as.ggplot = TRUE, show_labels = FALSE)
####################################################################
library(tidyverse)
library(magrittr)
library(cluster)
library(cluster.datasets)
library(cowplot)
library(NbClust)
library(clValid)
library(ggfortify)
library(clustree)
library(dendextend)
library(factoextra)
library(FactoMineR)
library(corrplot)
library(GGally)
library(ggiraphExtra)
library(knitr)
library(kableExtra)
install.packages(c("ggiraphExtra", "cluster.datasets", "cowplot", "NbClust", "clValid", "ggfortify", "clustree", "dendextend"))
library(tidyverse)
library(magrittr)
library(cluster)
library(cluster.datasets)
library(cowplot)
library(NbClust)
library(clValid)
library(ggfortify)
library(clustree)
library(dendextend)
library(factoextra)
library(FactoMineR)
library(corrplot)
library(GGally)
library(ggiraphExtra)
library(knitr)
library(kableExtra)
library(tidyverse)
library(magrittr)
library(cluster)
library(cluster.datasets)
library(cowplot)
library(NbClust)
library(clValid)
library(ggfortify)
library(clustree)
library(dendextend)
library(factoextra)
library(FactoMineR)
library(corrplot)
library(GGally)
library(ggiraphExtra)
library(knitr)
library(kableExtra)
install.packages("GGally")
library(GGally)
data("all.mammals.milk.1956")
raw_mammals <- all.mammals.milk.1956
# subset dataset
mammals <- raw_mammals %>% select(-name) # set rownames
mammals <- as_tibble(mammals)
# Glimpse the data set
glimpse(mammals)
# Summary of data set
summary(mammals) %>% kable() %>% kable_styling()
mammals %>%
gather(Attributes, value, 1:5) %>%
ggplot(aes(x=value)) +
geom_histogram(fill = "lightblue2", color = "black") +
facet_wrap(~Attributes, scales = "free_x") +
labs(x = "Value", y = "Frequency")
corrplot(cor(mammals), type = "upper", method = "ellipse", tl.cex = 0.9)
mammals_scaled <- scale(mammals)
rownames(mammals_scaled) <- raw_mammals$name
rsconnect::setAccountInfo(name='utkarsh-verma',
token='F10F5B9540C1EC8905208EA61AD2FF98',
secret='<SECRET>')
install.packages(c("caret", "DataExplorer", "foreign", "recipes", "RSQLite"))
shiny::runApp('D:/Programs/R/R_Sessions/First_Shiny App')
require(rsconnect)
?rsconnect::setAccountInfo
rsconnect::setAccountInfo(name='utkarsh-verma',
token='F10F5B9540C1EC8905208EA61AD2FF98',
secret='H2RDwYhVNZ0mm+edrvn/kVMRkBtrkbYv6ajxSrvz')
httr::GET("https://wd5-services1.myworkday.com/ccx/service/customreport2/")
require(c("curl","httr"))
require(curl)
require(httr)
rsconnect::setAccountInfo(name='utkarsh-verma',
token='F10F5B9540C1EC8905208EA61AD2FF98',
secret='H2RDwYhVNZ0mm+edrvn/kVMRkBtrkbYv6ajxSrvz')
require(rsconnect)
rsconnect::setAccountInfo(name='utkarsh-verma',
token='F10F5B9540C1EC8905208EA61AD2FF98',
secret='H2RDwYhVNZ0mm+edrvn/kVMRkBtrkbYv6ajxSrvz')
getwd()
setwd("D:\\Programs\\R\\R_Sessions")
getwd
getwd()
# clear the workspace
rm(list=ls())
# ensure the process is reproducible
set.seed(2)
library(carat)
library(caret)
data("iris")
dim(iris)
iris[sample(nrow(iris),100),]
table(iris$Species)
prb <- ifelse(iris$Species =="setosa",0.25, 0.75)
smpl<- iris[sample(nrow(iris), 524, prob = prb),]
table(smpl$Class)
smpl<- iris[sample(nrow(iris),100, prob = prb),]
table(smpl$Class)
prb <- ifelse(iris$Species =="setosa",0.25, 0.75)
smpl<- iris[sample(nrow(iris),100, prob = prb),]
table(smpl$Class)
table(smpl$Species)
plot(iris$Species)
plot(smpl$Species)
# Random Sampleing CreateDataPartation
library(caret)
# Random Sampleing CreateDataPartation
library(caret)
train.rows<- createDataPartition(y=iris$Species, p=0.7, list = FALSE)
train.data<- iris[train.rows,] # 70% data goes in here
table(train.data$Species)
# Random Sampleing CreateDataPartation
library(caret)
train.rows<- createDataPartition(y=iris$Species, p=0.7, list = FALSE)
train.data<- iris[train.rows,] # 70% data goes in here
test.data<- BreastCancer[-train.rows,] # 30% data goes in here
table(test.data$Species)
train.rows<- createDataPartition(y=iris$Species, p=0.7, list = FALSE)
train.data<- iris[train.rows,] # 70% data goes in here
test.data<- iris[-train.rows,] # 30% data goes in here
table(test.data$Species)
table(train.data$Species)
plot(train.data$Species)
plot(test.data$Species)
plot(train.data$Species)
df <- data_frame(
name = c("Animals", "Fruits", "Cars"),
y = c(5, 2, 4),
drilldown = tolower(name)
)
library(dplyr)
require(highcharter)
require(purrr)
df <- data_frame(
name = c("Animals", "Fruits", "Cars"),
y = c(5, 2, 4),
drilldown = tolower(name)
)
View(df)
ds <- list_parse(df)
names(ds) <- NULL
# BASIC DRILL DOWN Example
getwd()
setwd("D:\\Programs\\R\\R_Sessions")
library(dplyr)
require(highcharter)
require(purrr)
df <- data_frame(
name = c("Animals", "Fruits", "Cars"),
y = c(5, 2, 4),
drilldown = tolower(name)
)
ds <- list_parse(df)
names(ds) <- NULL
hc <- highchart() %>%
hc_chart(type = "column") %>%
hc_title(text = "Basic drilldown") %>%
hc_xAxis(type = "category") %>%
hc_legend(enabled = FALSE) %>%
hc_plotOptions(
series = list(
boderWidth = 0,
dataLabels = list(enabled = TRUE)
)
) %>%
hc_add_series(
name = "Things",
colorByPoint = TRUE,
data = ds
)
dfan <- data_frame(
name = c("Cats", "Dogs", "Cows", "Sheep", "Pigs"),
value = c(4, 3, 1, 2, 1)
)
dffru <- data_frame(
name = c("Apple", "Organes"),
value = c(4, 2)
)
dfcar <- data_frame(
name = c("Toyota", "Opel", "Volkswage"),
value = c(4, 2, 2)
)
second_el_to_numeric <- function(ls){
map(ls, function(x){
x[[2]] <- as.numeric(x[[2]])
x
})
}
dsan <- second_el_to_numeric(list_parse2(dfan))
dsfru <- second_el_to_numeric(list_parse2(dffru))
dscar <- second_el_to_numeric(list_parse2(dfcar))
hc %>%
hc_drilldown(
allowPointDrilldown = TRUE,
series = list(
list(
id = "animals",
data = dsan
),
list(
id = "fruits",
data = dsfru
),
list(
id = "cars",
data = dscar
)
)
)
